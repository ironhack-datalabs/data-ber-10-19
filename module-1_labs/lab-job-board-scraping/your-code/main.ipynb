{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Board Scraping Lab\n",
    "\n",
    "In this lab you will first see a minimal but fully functional code snippet to scrape the LinkedIn Job Search webpage. You will then work on top of the example code and complete several chanllenges.\n",
    "\n",
    "### Some Resources \n",
    "\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search(keywords):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    # Assemble the full url with parameters\n",
    "    scrape_url = ''.join([BASE_URL, 'keywords=', keywords])\n",
    "\n",
    "    # Create a request to get the data from the server \n",
    "    page = requests.get(scrape_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "    # Then in each job card, extract the job title, company, and location data.\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    for card in soup.select(\"div.result-card__contents\"):\n",
    "        title = card.findChild(\"h3\", recursive=False)\n",
    "        company = card.findChild(\"h4\", recursive=False)\n",
    "        location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "        titles.append(title.string)\n",
    "        companies.append(company.string)\n",
    "        locations.append(location.string)\n",
    "    \n",
    "    # Inject job titles, companies, and locations into the empty dataframe\n",
    "    zipped = zip(titles, companies, locations)\n",
    "    for z in list(zipped):\n",
    "        data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    # Return dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Master Data Management Architect /Manager</td>\n",
       "      <td>Synergy Business Consulting, Inc.</td>\n",
       "      <td>Teaneck, New Jersey, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEO Manager</td>\n",
       "      <td>Onward Select</td>\n",
       "      <td>Atlanta, Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Governance Analyst</td>\n",
       "      <td>Momentum Consulting Corporation</td>\n",
       "      <td>Miami, Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Systems Analyst</td>\n",
       "      <td>Cypress HCM</td>\n",
       "      <td>San Francisco, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst w/ AWS</td>\n",
       "      <td>Digipulse Technologies Inc.</td>\n",
       "      <td>Greensboro, North Carolina, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rebate &amp; Data Analyst (Contract)</td>\n",
       "      <td>SolomonEdwards</td>\n",
       "      <td>Philadelphia, Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tibco Spotfire Data Analyst</td>\n",
       "      <td>GSquared Group</td>\n",
       "      <td>Atlanta, Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Confiance Tech Solutions</td>\n",
       "      <td>Greater Atlanta Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HEDIS Quality Analyst</td>\n",
       "      <td>HealthTECH Resources, Inc.</td>\n",
       "      <td>New York, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Financial Analyst</td>\n",
       "      <td>Talent 360 Solutions</td>\n",
       "      <td>Greater Atlanta Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manager of Business Intelligence</td>\n",
       "      <td>Beyond Finance, Inc.</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manager, Provider Network Development (Healthc...</td>\n",
       "      <td>Remedy Partners</td>\n",
       "      <td>Norwalk, Connecticut, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IFRS9/CECL Implementation</td>\n",
       "      <td>New York Technology Partners</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Medical Director Pharmacovigilance</td>\n",
       "      <td>Integrated Resources, Inc ( IRI )</td>\n",
       "      <td>Cambridge, Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sr. Internal Auditor</td>\n",
       "      <td>Interface</td>\n",
       "      <td>1280 W Peachtree St NW, Atlanta, Georgia 30309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Workday Consultant</td>\n",
       "      <td>Amiseq Inc.</td>\n",
       "      <td>Frisco, Texas, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vice President - Counter Party Credit</td>\n",
       "      <td>Madison-Davis, LLC</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>WorkFusion</td>\n",
       "      <td>New York City, NY, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Manager Data Analysis</td>\n",
       "      <td>Jobs @ TheJobNetwork</td>\n",
       "      <td>Deerfield, IL, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ipsy</td>\n",
       "      <td>San Mateo, CA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Headspace Inc.</td>\n",
       "      <td>Santa Monica, CA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Master Data Analyst</td>\n",
       "      <td>Larsen &amp; Toubro Infotech Ltd (LTI)</td>\n",
       "      <td>San Jose, California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Senior Data Analyst - Finance &amp; Platform Analy...</td>\n",
       "      <td>Twitch</td>\n",
       "      <td>San Francisco, CA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Procurement Specialist â€“ MRO, Data Analysis</td>\n",
       "      <td>Blue Signal Search</td>\n",
       "      <td>Decatur, IL, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Operations Data Analyst &amp; Program Manager - 74307</td>\n",
       "      <td>AMD</td>\n",
       "      <td>Santa Clara, CA, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0           Master Data Management Architect /Manager   \n",
       "1                                         SEO Manager   \n",
       "2                             Data Governance Analyst   \n",
       "3                                Data Systems Analyst   \n",
       "4                                 Data Analyst w/ AWS   \n",
       "5                    Rebate & Data Analyst (Contract)   \n",
       "6                         Tibco Spotfire Data Analyst   \n",
       "7                                        Data Modeler   \n",
       "8                               HEDIS Quality Analyst   \n",
       "9                            Senior Financial Analyst   \n",
       "10                   Manager of Business Intelligence   \n",
       "11  Manager, Provider Network Development (Healthc...   \n",
       "12                          IFRS9/CECL Implementation   \n",
       "13                 Medical Director Pharmacovigilance   \n",
       "14                               Sr. Internal Auditor   \n",
       "15                                 Workday Consultant   \n",
       "16              Vice President - Counter Party Credit   \n",
       "17                                       Data Analyst   \n",
       "18                       Senior Manager Data Analysis   \n",
       "19                                       Data Analyst   \n",
       "20                                       Data Analyst   \n",
       "21                                Master Data Analyst   \n",
       "22  Senior Data Analyst - Finance & Platform Analy...   \n",
       "23        Procurement Specialist â€“ MRO, Data Analysis   \n",
       "24  Operations Data Analyst & Program Manager - 74307   \n",
       "\n",
       "                               Company  \\\n",
       "0    Synergy Business Consulting, Inc.   \n",
       "1                        Onward Select   \n",
       "2      Momentum Consulting Corporation   \n",
       "3                          Cypress HCM   \n",
       "4          Digipulse Technologies Inc.   \n",
       "5                       SolomonEdwards   \n",
       "6                       GSquared Group   \n",
       "7             Confiance Tech Solutions   \n",
       "8           HealthTECH Resources, Inc.   \n",
       "9                 Talent 360 Solutions   \n",
       "10                Beyond Finance, Inc.   \n",
       "11                     Remedy Partners   \n",
       "12        New York Technology Partners   \n",
       "13   Integrated Resources, Inc ( IRI )   \n",
       "14                           Interface   \n",
       "15                         Amiseq Inc.   \n",
       "16                  Madison-Davis, LLC   \n",
       "17                          WorkFusion   \n",
       "18                Jobs @ TheJobNetwork   \n",
       "19                                ipsy   \n",
       "20                      Headspace Inc.   \n",
       "21  Larsen & Toubro Infotech Ltd (LTI)   \n",
       "22                              Twitch   \n",
       "23                  Blue Signal Search   \n",
       "24                                 AMD   \n",
       "\n",
       "                                          Location  \n",
       "0               Teaneck, New Jersey, United States  \n",
       "1                                 Atlanta, Georgia  \n",
       "2                                   Miami, Florida  \n",
       "3                        San Francisco, California  \n",
       "4        Greensboro, North Carolina, United States  \n",
       "5                       Philadelphia, Pennsylvania  \n",
       "6                                 Atlanta, Georgia  \n",
       "7                             Greater Atlanta Area  \n",
       "8                               New York, New York  \n",
       "9                             Greater Atlanta Area  \n",
       "10                                  Houston, Texas  \n",
       "11             Norwalk, Connecticut, United States  \n",
       "12               New York, New York, United States  \n",
       "13                        Cambridge, Massachusetts  \n",
       "14  1280 W Peachtree St NW, Atlanta, Georgia 30309  \n",
       "15                    Frisco, Texas, United States  \n",
       "16               New York, New York, United States  \n",
       "17                           New York City, NY, US  \n",
       "18                               Deerfield, IL, US  \n",
       "19                               San Mateo, CA, US  \n",
       "20                            Santa Monica, CA, US  \n",
       "21             San Jose, California, United States  \n",
       "22                           San Francisco, CA, US  \n",
       "23                                 Decatur, IL, US  \n",
       "24                             Santa Clara, CA, US  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to call the function\n",
    "\n",
    "results = scrape_linkedin_job_search('data%20analysis')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "The first challenge for you is to update the `scrape_linkedin_job_search` function by adding a new parameter called `num_pages`. This will allow you to search more than 25 jobs with this function. Suggested steps:\n",
    "\n",
    "1. Go to https://www.linkedin.com/jobs/search/?keywords=data%20analysis in your browser.\n",
    "1. Scroll down the left panel and click the page 2 link. Look at how the URL changes and identify the page offset parameter.\n",
    "1. Add `num_pages` as a new param to the `scrape_linkedin_job_search` function. Update the function code so that it uses a \"for\" loop to retrieve several pages of search results.\n",
    "1. Test your new function by scraping 5 pages of the search results.\n",
    "\n",
    "Hint: Prepare for the case where there are less than 5 pages of search results. Your function should be robust enough to **not** trigger errors. Simply skip making additional searches and return all results if the search already reaches the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "#https://www.linkedin.com/jobs/search/?keywords=data%20analysis\n",
    "#https://www.linkedin.com/jobs/search/?keywords=data%20analysis&start=25\n",
    "\n",
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search_1(keywords, num_pages):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for page in range(num_pages):\n",
    "        # Assemble the full url with parameters\n",
    "        scrape_url = ''.join([BASE_URL, 'keywords=', keywords, '&start=', str(page*25)])\n",
    "\n",
    "        # Create a request to get the data from the server \n",
    "        page = requests.get(scrape_url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "        # Then in each job card, extract the job title, company, and location data.\n",
    "        titles = []\n",
    "        companies = []\n",
    "        locations = []\n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "\n",
    "        # Inject job titles, companies, and locations into the empty dataframe\n",
    "        zipped = zip(titles, companies, locations)\n",
    "        for z in list(zipped):\n",
    "            data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "\n",
    "    # Return dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sr. Data Analyst â€“ Predictive &amp; Inferential An...</td>\n",
       "      <td>Peyton Resource Group</td>\n",
       "      <td>Arlington, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Senior Manager of Data Analysis</td>\n",
       "      <td>Philips</td>\n",
       "      <td>Boston, MA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Software Engineer, Data Models &amp; Analysis</td>\n",
       "      <td>Improbable</td>\n",
       "      <td>Washington, D.C., DC, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Data Analysis Manager</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>McLean, VA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BUSINESS ANALYST-Marketing and Data Analysis</td>\n",
       "      <td>ASHLIN Management Group</td>\n",
       "      <td>20721, Bowie, Maryland, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>Associate / Business Analyst (Consulting Data ...</td>\n",
       "      <td>Foresight Associates, LLC</td>\n",
       "      <td>Greater Minneapolis-St. Paul Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>Intern: Data Analysis/Process Improvement Prog...</td>\n",
       "      <td>Juniper Networks</td>\n",
       "      <td>Sunnyvale, CA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>Manager, Reporting and Data Analysis</td>\n",
       "      <td>The Madison Square Garden Company</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Viper Staffing Services L.L.C.</td>\n",
       "      <td>Glendale, California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>Sr. Bioinformatics Scientist</td>\n",
       "      <td>The EAC Agency</td>\n",
       "      <td>Fremont, California, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   Sr. Data Analyst â€“ Predictive & Inferential An...   \n",
       "1                     Senior Manager of Data Analysis   \n",
       "2           Software Engineer, Data Models & Analysis   \n",
       "3                               Data Analysis Manager   \n",
       "4        BUSINESS ANALYST-Marketing and Data Analysis   \n",
       "..                                                ...   \n",
       "95  Associate / Business Analyst (Consulting Data ...   \n",
       "96  Intern: Data Analysis/Process Improvement Prog...   \n",
       "97               Manager, Reporting and Data Analysis   \n",
       "98                                       Data Analyst   \n",
       "99                       Sr. Bioinformatics Scientist   \n",
       "\n",
       "                              Company                               Location  \n",
       "0               Peyton Resource Group                       Arlington, Texas  \n",
       "1                             Philips                         Boston, MA, US  \n",
       "2                          Improbable               Washington, D.C., DC, US  \n",
       "3                         Capital One                         McLean, VA, US  \n",
       "4             ASHLIN Management Group  20721, Bowie, Maryland, United States  \n",
       "..                                ...                                    ...  \n",
       "95          Foresight Associates, LLC      Greater Minneapolis-St. Paul Area  \n",
       "96                   Juniper Networks                      Sunnyvale, CA, US  \n",
       "97  The Madison Square Garden Company             Greater New York City Area  \n",
       "98     Viper Staffing Services L.L.C.    Glendale, California, United States  \n",
       "99                     The EAC Agency     Fremont, California, United States  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search_1('data%20analysis', 4)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "Further improve your function so that it can search jobs in a specific country. Add the 3rd param to your function called `country`. The steps are identical to those in Challange 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search_2(keywords, num_pages, country):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for page in range(num_pages):\n",
    "        # Assemble the full url with parameters\n",
    "        scrape_url = ''.join([BASE_URL, 'keywords=', keywords, '&start=', str(page*25), '&location=', country])\n",
    "\n",
    "        # Create a request to get the data from the server \n",
    "        page = requests.get(scrape_url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "        # Then in each job card, extract the job title, company, and location data.\n",
    "        titles = []\n",
    "        companies = []\n",
    "        locations = []\n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "\n",
    "        # Inject job titles, companies, and locations into the empty dataframe\n",
    "        zipped = zip(titles, companies, locations)\n",
    "        for z in list(zipped):\n",
    "            data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "\n",
    "    # Return dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>JLL</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data and Reporting Analyst</td>\n",
       "      <td>Toptal</td>\n",
       "      <td>DÃ©partement du Nord, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Software Engineer for Web Data Analysis</td>\n",
       "      <td>ESRF - The European Synchrotron</td>\n",
       "      <td>Grenoble Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist Internship, France</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Dashlane</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Engineering Manager - Data Platform Team - Ful...</td>\n",
       "      <td>Heetch</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Health Data Marketing Manager - Boulogne/Londo...</td>\n",
       "      <td>Cegedim</td>\n",
       "      <td>Boulogne-Billancourt, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Vulog</td>\n",
       "      <td>Nice Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Data Engineer (M/F)</td>\n",
       "      <td>Servier</td>\n",
       "      <td>Croissy-sur-Seine, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Data Analyst - Internal Analytics Platform</td>\n",
       "      <td>Datadog</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Data Analyst - Owlient</td>\n",
       "      <td>Ubisoft</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Danone Data Platforms Analyst H/F</td>\n",
       "      <td>Danone</td>\n",
       "      <td>Rueil-Malmaison, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Data Quality &amp; Governance Manager H/F</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Marketing Data Engineer / Analyst</td>\n",
       "      <td>Richemont</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Machine Learning Engineer - transfer learning ...</td>\n",
       "      <td>European Recruitment</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Data Warehouse Manager / Business Intelligence...</td>\n",
       "      <td>ArcelorMittal</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Internship - Data Scientist</td>\n",
       "      <td>Louis Dreyfus Company</td>\n",
       "      <td>Lyon, Auvergne-Rhone-Alpes, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Data Visualisation Designer</td>\n",
       "      <td>OECD - OCDE</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Data Analyst (M/F)</td>\n",
       "      <td>beIN MEDIA GROUP</td>\n",
       "      <td>Boulogne-Billancourt, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Data Master</td>\n",
       "      <td>Rexel</td>\n",
       "      <td>Paris 17, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Givaudan</td>\n",
       "      <td>Argenteuil, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Business Data Steward</td>\n",
       "      <td>Total</td>\n",
       "      <td>Pau, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Data Analyst- Marketing</td>\n",
       "      <td>Virtuo</td>\n",
       "      <td>Paris, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meero</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Growth Data Analyst</td>\n",
       "      <td>Getaround</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>JLL</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>komoot</td>\n",
       "      <td>Paris, Ile-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Data and Reporting Analyst</td>\n",
       "      <td>Toptal</td>\n",
       "      <td>DÃ©partement du Nord, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Data Analyst - Internal Analytics Platform</td>\n",
       "      <td>Datadog</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Software Engineer for Web Data Analysis</td>\n",
       "      <td>ESRF - The European Synchrotron</td>\n",
       "      <td>Grenoble Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Givaudan</td>\n",
       "      <td>Argenteuil, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Dashlane</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Vulog</td>\n",
       "      <td>Nice Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Product Data Analyst Lead</td>\n",
       "      <td>Criteo</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Human Resources Data Analyst</td>\n",
       "      <td>CWT</td>\n",
       "      <td>Boulogne-Billancourt, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Data Analyst - Owlient</td>\n",
       "      <td>Ubisoft</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Engineering Manager - Data Platform Team - Ful...</td>\n",
       "      <td>Heetch</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Master Data Analyst</td>\n",
       "      <td>MAETRICS</td>\n",
       "      <td>Montpellier Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Machine Learning Engineer - transfer learning ...</td>\n",
       "      <td>European Recruitment</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Data Engineer (M/F)</td>\n",
       "      <td>Servier</td>\n",
       "      <td>Croissy-sur-Seine, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Data Visualisation Designer</td>\n",
       "      <td>OECD - OCDE</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Internship - Data Scientist</td>\n",
       "      <td>Louis Dreyfus Company</td>\n",
       "      <td>Lyon, Auvergne-Rhone-Alpes, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Sales Operations Analyst</td>\n",
       "      <td>SUEZ</td>\n",
       "      <td>Courbevoie, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Marketing Data Engineer / Analyst</td>\n",
       "      <td>Richemont</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Senior Technical Consultant for Data Analytics</td>\n",
       "      <td>MathWorks</td>\n",
       "      <td>Meudon, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Data Master</td>\n",
       "      <td>Rexel</td>\n",
       "      <td>Paris 17, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Danone Data Platforms Analyst H/F</td>\n",
       "      <td>Danone</td>\n",
       "      <td>Rueil-Malmaison, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Data Analyst- Marketing</td>\n",
       "      <td>Virtuo</td>\n",
       "      <td>Paris, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>Credit Analyst - International Public Finance ...</td>\n",
       "      <td>Fitch Ratings</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>Business Data Steward</td>\n",
       "      <td>Total</td>\n",
       "      <td>Pau, FR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                 Senior Data Analyst   \n",
       "1                          Data and Reporting Analyst   \n",
       "2             Software Engineer for Web Data Analysis   \n",
       "3                   Data Scientist Internship, France   \n",
       "4                                 Data Analyst Intern   \n",
       "5   Engineering Manager - Data Platform Team - Ful...   \n",
       "6   Health Data Marketing Manager - Boulogne/Londo...   \n",
       "7                                      Data Scientist   \n",
       "8                                 Data Engineer (M/F)   \n",
       "9          Data Analyst - Internal Analytics Platform   \n",
       "10                             Data Analyst - Owlient   \n",
       "11                  Danone Data Platforms Analyst H/F   \n",
       "12              Data Quality & Governance Manager H/F   \n",
       "13                  Marketing Data Engineer / Analyst   \n",
       "14  Machine Learning Engineer - transfer learning ...   \n",
       "15  Data Warehouse Manager / Business Intelligence...   \n",
       "16                        Internship - Data Scientist   \n",
       "17                        Data Visualisation Designer   \n",
       "18                                 Data Analyst (M/F)   \n",
       "19                                        Data Master   \n",
       "20                                Junior Data Analyst   \n",
       "21                              Business Data Steward   \n",
       "22                            Data Analyst- Marketing   \n",
       "23                                       Data Analyst   \n",
       "24                                Growth Data Analyst   \n",
       "25                                Senior Data Analyst   \n",
       "26                                Senior Data Analyst   \n",
       "27                         Data and Reporting Analyst   \n",
       "28         Data Analyst - Internal Analytics Platform   \n",
       "29            Software Engineer for Web Data Analysis   \n",
       "30                                Junior Data Analyst   \n",
       "31                                       Data Analyst   \n",
       "32                                     Data Scientist   \n",
       "33                          Product Data Analyst Lead   \n",
       "34                       Human Resources Data Analyst   \n",
       "35                             Data Analyst - Owlient   \n",
       "36  Engineering Manager - Data Platform Team - Ful...   \n",
       "37                                Master Data Analyst   \n",
       "38  Machine Learning Engineer - transfer learning ...   \n",
       "39                                Data Engineer (M/F)   \n",
       "40                        Data Visualisation Designer   \n",
       "41                        Internship - Data Scientist   \n",
       "42                           Sales Operations Analyst   \n",
       "43                  Marketing Data Engineer / Analyst   \n",
       "44     Senior Technical Consultant for Data Analytics   \n",
       "45                                        Data Master   \n",
       "46                  Danone Data Platforms Analyst H/F   \n",
       "47                            Data Analyst- Marketing   \n",
       "48  Credit Analyst - International Public Finance ...   \n",
       "49                              Business Data Steward   \n",
       "\n",
       "                            Company  \\\n",
       "0                               JLL   \n",
       "1                            Toptal   \n",
       "2   ESRF - The European Synchrotron   \n",
       "3                            Airbnb   \n",
       "4                          Dashlane   \n",
       "5                            Heetch   \n",
       "6                           Cegedim   \n",
       "7                             Vulog   \n",
       "8                           Servier   \n",
       "9                           Datadog   \n",
       "10                          Ubisoft   \n",
       "11                           Danone   \n",
       "12                      TripAdvisor   \n",
       "13                        Richemont   \n",
       "14             European Recruitment   \n",
       "15                    ArcelorMittal   \n",
       "16            Louis Dreyfus Company   \n",
       "17                      OECD - OCDE   \n",
       "18                 beIN MEDIA GROUP   \n",
       "19                            Rexel   \n",
       "20                         Givaudan   \n",
       "21                            Total   \n",
       "22                           Virtuo   \n",
       "23                            Meero   \n",
       "24                        Getaround   \n",
       "25                              JLL   \n",
       "26                           komoot   \n",
       "27                           Toptal   \n",
       "28                          Datadog   \n",
       "29  ESRF - The European Synchrotron   \n",
       "30                         Givaudan   \n",
       "31                         Dashlane   \n",
       "32                            Vulog   \n",
       "33                           Criteo   \n",
       "34                              CWT   \n",
       "35                          Ubisoft   \n",
       "36                           Heetch   \n",
       "37                         MAETRICS   \n",
       "38             European Recruitment   \n",
       "39                          Servier   \n",
       "40                      OECD - OCDE   \n",
       "41            Louis Dreyfus Company   \n",
       "42                             SUEZ   \n",
       "43                        Richemont   \n",
       "44                        MathWorks   \n",
       "45                            Rexel   \n",
       "46                           Danone   \n",
       "47                           Virtuo   \n",
       "48                    Fitch Ratings   \n",
       "49                            Total   \n",
       "\n",
       "                                       Location  \n",
       "0                            Paris Area, France  \n",
       "1                       DÃ©partement du Nord, FR  \n",
       "2                         Grenoble Area, France  \n",
       "3                                     Paris, FR  \n",
       "4                                     Paris, FR  \n",
       "5                                     Paris, FR  \n",
       "6                      Boulogne-Billancourt, FR  \n",
       "7                             Nice Area, France  \n",
       "8                         Croissy-sur-Seine, FR  \n",
       "9                                     Paris, FR  \n",
       "10                           Paris Area, France  \n",
       "11                          Rueil-Malmaison, FR  \n",
       "12                                    Paris, FR  \n",
       "13                                    Paris, FR  \n",
       "14                           Paris Area, France  \n",
       "15                           Paris Area, France  \n",
       "16           Lyon, Auvergne-Rhone-Alpes, France  \n",
       "17                           Paris Area, France  \n",
       "18  Boulogne-Billancourt, ÃŽle-de-France, France  \n",
       "19              Paris 17, ÃŽle-de-France, France  \n",
       "20                               Argenteuil, FR  \n",
       "21                                      Pau, FR  \n",
       "22                 Paris, ÃŽle-de-France, France  \n",
       "23                                    Paris, FR  \n",
       "24                                    Paris, FR  \n",
       "25                           Paris Area, France  \n",
       "26                 Paris, Ile-de-France, France  \n",
       "27                      DÃ©partement du Nord, FR  \n",
       "28                                    Paris, FR  \n",
       "29                        Grenoble Area, France  \n",
       "30                               Argenteuil, FR  \n",
       "31                                    Paris, FR  \n",
       "32                            Nice Area, France  \n",
       "33                                    Paris, FR  \n",
       "34                     Boulogne-Billancourt, FR  \n",
       "35                           Paris Area, France  \n",
       "36                                    Paris, FR  \n",
       "37                     Montpellier Area, France  \n",
       "38                           Paris Area, France  \n",
       "39                        Croissy-sur-Seine, FR  \n",
       "40                           Paris Area, France  \n",
       "41           Lyon, Auvergne-Rhone-Alpes, France  \n",
       "42                               Courbevoie, FR  \n",
       "43                                    Paris, FR  \n",
       "44                                   Meudon, FR  \n",
       "45              Paris 17, ÃŽle-de-France, France  \n",
       "46                          Rueil-Malmaison, FR  \n",
       "47                 Paris, ÃŽle-de-France, France  \n",
       "48                                    Paris, FR  \n",
       "49                                      Pau, FR  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search_2('data%20analysis', 2, 'Frankreich')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "Add the 4th param called `num_days` to your function to allow it to search jobs posted in the past X days. Note that in the LinkedIn job search the searched timespan is specified with the following param:\n",
    "\n",
    "```\n",
    "f_TPR=r259200\n",
    "```\n",
    "\n",
    "The number part in the param value is the number of seconds. 259,200 seconds equal to 3 days. You need to convert `num_days` to number of seconds and supply that info to LinkedIn job search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "#f_TPR=r86400\n",
    "\n",
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search_3(keywords, num_pages, country, num_days):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    num_seconds = num_days * 86400\n",
    "    \n",
    "    for page in range(num_pages):\n",
    "        # Assemble the full url with parameters\n",
    "        scrape_url = ''.join([BASE_URL, 'f_TPR=r', str(num_seconds), 'keywords=', keywords, '&start=', str(page*25), '&location=', country])\n",
    "\n",
    "        # Create a request to get the data from the server \n",
    "        page = requests.get(scrape_url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "        # Then in each job card, extract the job title, company, and location data.\n",
    "        titles = []\n",
    "        companies = []\n",
    "        locations = []\n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "\n",
    "        # Inject job titles, companies, and locations into the empty dataframe\n",
    "        zipped = zip(titles, companies, locations)\n",
    "        for z in list(zipped):\n",
    "            data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "\n",
    "    # Return dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Consultant fonctionnel</td>\n",
       "      <td>HELYAD</td>\n",
       "      <td>NÃ®mes et pÃ©riphÃ©rie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Agent de planification</td>\n",
       "      <td>PRIVACIA RECYCLAGE</td>\n",
       "      <td>Noisy-le-Sec, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Consultant Ressources Humaines</td>\n",
       "      <td>Omnicell</td>\n",
       "      <td>Vendenheim, Grand Est, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Technicien informatique</td>\n",
       "      <td>Peninsula Paris</td>\n",
       "      <td>75116, Paris, Ile-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Employer Brand and Events Manager</td>\n",
       "      <td>Mirakl</td>\n",
       "      <td>Paris, Ile-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Indexel</td>\n",
       "      <td>RÃ©gion de Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>E-Commerce Manager - StratÃ©gie et KAM - Multin...</td>\n",
       "      <td>IHR Consultancy</td>\n",
       "      <td>Paris 01, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>BÃ©nÃ©volat : Aide Ã  activitÃ© initiation multisp...</td>\n",
       "      <td>Tous BÃ©nÃ©voles</td>\n",
       "      <td>Dourdan, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Juriste droit des affaires 3/10 ans</td>\n",
       "      <td>OXYGEN+</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>CONSULTANT SOCIAL MEDIA (H/F) CDD 3 mois</td>\n",
       "      <td>BCW France</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Internal Communication Officer</td>\n",
       "      <td>International Chamber of Commerce</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>ChargÃ© de logisitique Junior (F/H)</td>\n",
       "      <td>GreenYellow</td>\n",
       "      <td>Paris 15, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>CDI - Lead UX (H/F)</td>\n",
       "      <td>Aquent France</td>\n",
       "      <td>RÃ©gion de Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>OFFICIERS MARINE MARCHANDE H/F</td>\n",
       "      <td>BOURBON</td>\n",
       "      <td>Marseille, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>responsable d'affaires activitÃ© industrielle</td>\n",
       "      <td>VINCI Energies</td>\n",
       "      <td>Fos-sur-Mer, Provence-Alpes-CÃ´te dâ€™Azur, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Consultant en dÃ©mÃ©nagement et mobilitÃ© interna...</td>\n",
       "      <td>Crown World Mobility</td>\n",
       "      <td>Poissy, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Pizzaiolo (H/F)</td>\n",
       "      <td>la maison</td>\n",
       "      <td>Lyon, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>TECHNICIEN EN DIAGNOSTIC DU BÃ‚TIMENT - CONTRAT...</td>\n",
       "      <td>Apave</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Aide soignant F/H H/F</td>\n",
       "      <td>AILE MEDICALE</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Magasinier PiÃ¨ces de Rechange Automobile (f/h)</td>\n",
       "      <td>GUEUDET</td>\n",
       "      <td>Ã‰vreux, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Assistant chargÃ© / Assistante chargÃ©e d'affair...</td>\n",
       "      <td>Axxis Ressources</td>\n",
       "      <td>Lieusaint, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Responsable de dÃ©veloppement my digital school...</td>\n",
       "      <td>AFTEC</td>\n",
       "      <td>Caen, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Responsable univers h/f</td>\n",
       "      <td>Boulanger</td>\n",
       "      <td>Dijon, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Commis de restauration room service</td>\n",
       "      <td>Vendome Group</td>\n",
       "      <td>Paris, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>IngÃ©nieur Test Logiciel</td>\n",
       "      <td>2s2i Groupe</td>\n",
       "      <td>Montpellier, FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Consultant fonctionnel</td>\n",
       "      <td>HELYAD</td>\n",
       "      <td>NÃ®mes et pÃ©riphÃ©rie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>ChargÃ©(e) d'Ã©tudes merchandising F/H</td>\n",
       "      <td>SYSTEME U</td>\n",
       "      <td>Carquefou, Pays de la Loire, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Consultant Ressources Humaines</td>\n",
       "      <td>Omnicell</td>\n",
       "      <td>Vendenheim, Grand Est, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Technicien informatique</td>\n",
       "      <td>Peninsula Paris</td>\n",
       "      <td>75116, Paris, Ile-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Agent de planification</td>\n",
       "      <td>PRIVACIA RECYCLAGE</td>\n",
       "      <td>Noisy-le-Sec, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Employer Brand and Events Manager</td>\n",
       "      <td>Mirakl</td>\n",
       "      <td>Paris, Ile-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Indexel</td>\n",
       "      <td>RÃ©gion de Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>E-Commerce Manager - StratÃ©gie et KAM - Multin...</td>\n",
       "      <td>IHR Consultancy</td>\n",
       "      <td>Paris 01, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Juriste droit des affaires 3/10 ans</td>\n",
       "      <td>OXYGEN+</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>CONSULTANT SOCIAL MEDIA (H/F) CDD 3 mois</td>\n",
       "      <td>BCW France</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Conseiller Commercial MarchÃ© des Particuliers ...</td>\n",
       "      <td>Groupama d'Oc</td>\n",
       "      <td>Florac, Languedoc-Roussillon, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>DÃ©monstrateur H/F - Tommy Hilfiger - Printemps...</td>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>VÃ©lizy-Villacoublay, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Vendeur automobile</td>\n",
       "      <td>Audexia SAS</td>\n",
       "      <td>Saint-Doulchard, Centre-Val de Loire, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Consultant(e) communication expÃ©rimentÃ©(e)</td>\n",
       "      <td>D-Impulse</td>\n",
       "      <td>Rouen, Haute-Normandie, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Directeur Clients Nationaux GMS</td>\n",
       "      <td>Haudecoeur</td>\n",
       "      <td>Paris, Ile-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Chef d'Atelier SAV</td>\n",
       "      <td>NOVAERA SERVICES</td>\n",
       "      <td>RÃ©gion de Toulouse, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>ContrÃ´leur de Gestion Junior</td>\n",
       "      <td>ACTING</td>\n",
       "      <td>Aix-en-Provence, Provence-Alpes-CÃ´te dâ€™Azur, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>ChargÃ© de logisitique Junior (F/H)</td>\n",
       "      <td>GreenYellow</td>\n",
       "      <td>Paris 15, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>KERING EYEWEAR - Trade Marketing Intern</td>\n",
       "      <td>Kering Eyewear</td>\n",
       "      <td>Paris Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Regulatory Affairs Specialist</td>\n",
       "      <td>MAETRICS</td>\n",
       "      <td>Lyon Area, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Compensation and Benefits Manager H/F</td>\n",
       "      <td>Publicis Sapient</td>\n",
       "      <td>RÃ©gion de Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Business Developer - Industrie Pharmaceutique</td>\n",
       "      <td>AIXIAL</td>\n",
       "      <td>Boulogne-Billancourt, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Contract Manager</td>\n",
       "      <td>Cellnex Telecom</td>\n",
       "      <td>SÃ¨vres, ÃŽle-de-France, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>CDI - Lead UX (H/F)</td>\n",
       "      <td>Aquent France</td>\n",
       "      <td>RÃ©gion de Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>Consultant dÃ©cisionnel Business Intelligence c...</td>\n",
       "      <td>DeciVision</td>\n",
       "      <td>Lyon 01, RhÃ´ne-Alpes, France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                              Consultant fonctionnel   \n",
       "1                              Agent de planification   \n",
       "2                      Consultant Ressources Humaines   \n",
       "3                             Technicien informatique   \n",
       "4                   Employer Brand and Events Manager   \n",
       "5                                     Project Manager   \n",
       "6   E-Commerce Manager - StratÃ©gie et KAM - Multin...   \n",
       "7   BÃ©nÃ©volat : Aide Ã  activitÃ© initiation multisp...   \n",
       "8                 Juriste droit des affaires 3/10 ans   \n",
       "9            CONSULTANT SOCIAL MEDIA (H/F) CDD 3 mois   \n",
       "10                     Internal Communication Officer   \n",
       "11                 ChargÃ© de logisitique Junior (F/H)   \n",
       "12                                CDI - Lead UX (H/F)   \n",
       "13                     OFFICIERS MARINE MARCHANDE H/F   \n",
       "14       responsable d'affaires activitÃ© industrielle   \n",
       "15  Consultant en dÃ©mÃ©nagement et mobilitÃ© interna...   \n",
       "16                                    Pizzaiolo (H/F)   \n",
       "17  TECHNICIEN EN DIAGNOSTIC DU BÃ‚TIMENT - CONTRAT...   \n",
       "18                              Aide soignant F/H H/F   \n",
       "19     Magasinier PiÃ¨ces de Rechange Automobile (f/h)   \n",
       "20  Assistant chargÃ© / Assistante chargÃ©e d'affair...   \n",
       "21  Responsable de dÃ©veloppement my digital school...   \n",
       "22                            Responsable univers h/f   \n",
       "23                Commis de restauration room service   \n",
       "24                            IngÃ©nieur Test Logiciel   \n",
       "25                             Consultant fonctionnel   \n",
       "26               ChargÃ©(e) d'Ã©tudes merchandising F/H   \n",
       "27                     Consultant Ressources Humaines   \n",
       "28                            Technicien informatique   \n",
       "29                             Agent de planification   \n",
       "30                  Employer Brand and Events Manager   \n",
       "31                                    Project Manager   \n",
       "32  E-Commerce Manager - StratÃ©gie et KAM - Multin...   \n",
       "33                Juriste droit des affaires 3/10 ans   \n",
       "34           CONSULTANT SOCIAL MEDIA (H/F) CDD 3 mois   \n",
       "35  Conseiller Commercial MarchÃ© des Particuliers ...   \n",
       "36  DÃ©monstrateur H/F - Tommy Hilfiger - Printemps...   \n",
       "37                                 Vendeur automobile   \n",
       "38         Consultant(e) communication expÃ©rimentÃ©(e)   \n",
       "39                    Directeur Clients Nationaux GMS   \n",
       "40                                 Chef d'Atelier SAV   \n",
       "41                       ContrÃ´leur de Gestion Junior   \n",
       "42                 ChargÃ© de logisitique Junior (F/H)   \n",
       "43            KERING EYEWEAR - Trade Marketing Intern   \n",
       "44                      Regulatory Affairs Specialist   \n",
       "45              Compensation and Benefits Manager H/F   \n",
       "46      Business Developer - Industrie Pharmaceutique   \n",
       "47                                  Contract Manager    \n",
       "48                                CDI - Lead UX (H/F)   \n",
       "49  Consultant dÃ©cisionnel Business Intelligence c...   \n",
       "\n",
       "                              Company  \\\n",
       "0                              HELYAD   \n",
       "1                  PRIVACIA RECYCLAGE   \n",
       "2                            Omnicell   \n",
       "3                     Peninsula Paris   \n",
       "4                              Mirakl   \n",
       "5                             Indexel   \n",
       "6                     IHR Consultancy   \n",
       "7                      Tous BÃ©nÃ©voles   \n",
       "8                             OXYGEN+   \n",
       "9                          BCW France   \n",
       "10  International Chamber of Commerce   \n",
       "11                        GreenYellow   \n",
       "12                      Aquent France   \n",
       "13                            BOURBON   \n",
       "14                     VINCI Energies   \n",
       "15               Crown World Mobility   \n",
       "16                          la maison   \n",
       "17                              Apave   \n",
       "18                      AILE MEDICALE   \n",
       "19                            GUEUDET   \n",
       "20                   Axxis Ressources   \n",
       "21                              AFTEC   \n",
       "22                          Boulanger   \n",
       "23                      Vendome Group   \n",
       "24                        2s2i Groupe   \n",
       "25                             HELYAD   \n",
       "26                          SYSTEME U   \n",
       "27                           Omnicell   \n",
       "28                    Peninsula Paris   \n",
       "29                 PRIVACIA RECYCLAGE   \n",
       "30                             Mirakl   \n",
       "31                            Indexel   \n",
       "32                    IHR Consultancy   \n",
       "33                            OXYGEN+   \n",
       "34                         BCW France   \n",
       "35                      Groupama d'Oc   \n",
       "36                     Tommy Hilfiger   \n",
       "37                        Audexia SAS   \n",
       "38                         D-Impulse    \n",
       "39                         Haudecoeur   \n",
       "40                   NOVAERA SERVICES   \n",
       "41                             ACTING   \n",
       "42                        GreenYellow   \n",
       "43                     Kering Eyewear   \n",
       "44                           MAETRICS   \n",
       "45                   Publicis Sapient   \n",
       "46                             AIXIAL   \n",
       "47                    Cellnex Telecom   \n",
       "48                      Aquent France   \n",
       "49                         DeciVision   \n",
       "\n",
       "                                             Location  \n",
       "0                                 NÃ®mes et pÃ©riphÃ©rie  \n",
       "1                 Noisy-le-Sec, ÃŽle-de-France, France  \n",
       "2                       Vendenheim, Grand Est, France  \n",
       "3                 75116, Paris, Ile-de-France, France  \n",
       "4                        Paris, Ile-de-France, France  \n",
       "5                             RÃ©gion de Paris, France  \n",
       "6                     Paris 01, ÃŽle-de-France, France  \n",
       "7                                         Dourdan, FR  \n",
       "8                                  Paris Area, France  \n",
       "9                                  Paris Area, France  \n",
       "10                                              Paris  \n",
       "11                    Paris 15, ÃŽle-de-France, France  \n",
       "12                            RÃ©gion de Paris, France  \n",
       "13                                      Marseille, FR  \n",
       "14    Fos-sur-Mer, Provence-Alpes-CÃ´te dâ€™Azur, France  \n",
       "15                      Poissy, ÃŽle-de-France, France  \n",
       "16                                           Lyon, FR  \n",
       "17                                          Paris, FR  \n",
       "18                                          Paris, FR  \n",
       "19                                         Ã‰vreux, FR  \n",
       "20                                      Lieusaint, FR  \n",
       "21                                           Caen, FR  \n",
       "22                                          Dijon, FR  \n",
       "23                                          Paris, FR  \n",
       "24                                    Montpellier, FR  \n",
       "25                                NÃ®mes et pÃ©riphÃ©rie  \n",
       "26                Carquefou, Pays de la Loire, France  \n",
       "27                      Vendenheim, Grand Est, France  \n",
       "28                75116, Paris, Ile-de-France, France  \n",
       "29                Noisy-le-Sec, ÃŽle-de-France, France  \n",
       "30                       Paris, Ile-de-France, France  \n",
       "31                            RÃ©gion de Paris, France  \n",
       "32                    Paris 01, ÃŽle-de-France, France  \n",
       "33                                 Paris Area, France  \n",
       "34                                 Paris Area, France  \n",
       "35               Florac, Languedoc-Roussillon, France  \n",
       "36         VÃ©lizy-Villacoublay, ÃŽle-de-France, France  \n",
       "37       Saint-Doulchard, Centre-Val de Loire, France  \n",
       "38                     Rouen, Haute-Normandie, France  \n",
       "39                       Paris, Ile-de-France, France  \n",
       "40                         RÃ©gion de Toulouse, France  \n",
       "41  Aix-en-Provence, Provence-Alpes-CÃ´te dâ€™Azur, F...  \n",
       "42                    Paris 15, ÃŽle-de-France, France  \n",
       "43                                 Paris Area, France  \n",
       "44                                  Lyon Area, France  \n",
       "45                            RÃ©gion de Paris, France  \n",
       "46        Boulogne-Billancourt, ÃŽle-de-France, France  \n",
       "47                      SÃ¨vres, ÃŽle-de-France, France  \n",
       "48                            RÃ©gion de Paris, France  \n",
       "49                       Lyon 01, RhÃ´ne-Alpes, France  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search_3('data%20analysis', 2, 'Frankreich', 3)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Allow your function to also retrieve the \"Seniority Level\" of each job searched. Note that the Seniority Level info is not in the initial search results. You need to make a separate search request for each job card based on the `currentJobId` value which you can extract from the job card HTML.\n",
    "\n",
    "After you obtain the Seniority Level info, update the function and add it to a new column of the returned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
