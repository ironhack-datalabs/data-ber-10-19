{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Board Scraping Lab\n",
    "\n",
    "In this lab you will first see a minimal but fully functional code snippet to scrape the LinkedIn Job Search webpage. You will then work on top of the example code and complete several chanllenges.\n",
    "\n",
    "### Some Resources \n",
    "\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search(keywords):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    # Assemble the full url with parameters\n",
    "    scrape_url = ''.join([BASE_URL, 'keywords=', keywords])\n",
    "\n",
    "    # Create a request to get the data from the server \n",
    "    page = requests.get(scrape_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "    # Then in each job card, extract the job title, company, and location data.\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    for card in soup.select(\"div.result-card__contents\"):\n",
    "        title = card.findChild(\"h3\", recursive=False)\n",
    "        company = card.findChild(\"h4\", recursive=False)\n",
    "        location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "        titles.append(title.string)\n",
    "        companies.append(company.string)\n",
    "        locations.append(location.string)\n",
    "    \n",
    "    # Inject job titles, companies, and locations into the empty dataframe\n",
    "    zipped = zip(titles, companies, locations)\n",
    "    for z in list(zipped):\n",
    "        data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    # Return dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IT Senior Associate</td>\n",
       "      <td>Kearney &amp; Company</td>\n",
       "      <td>McLean, VA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intern: Data Analysis/Process Improvement Prog...</td>\n",
       "      <td>Juniper Networks</td>\n",
       "      <td>Sunnyvale, CA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate / Business Analyst (Consulting Data ...</td>\n",
       "      <td>Foresight Associates, LLC</td>\n",
       "      <td>Greater Minneapolis-St. Paul Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineer, Data Models &amp; Analysis</td>\n",
       "      <td>Improbable</td>\n",
       "      <td>Washington, D.C., DC, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manager, Reporting and Data Analysis</td>\n",
       "      <td>The Madison Square Garden Company</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analysis Manager</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>McLean, VA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Management and Analysis Services Analyst I</td>\n",
       "      <td>Conduent</td>\n",
       "      <td>Ocoee, Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manager, Data Analysis &amp; Insights</td>\n",
       "      <td>The Coca-Cola Company</td>\n",
       "      <td>Atlanta, GA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Viper Staffing Services L.L.C.</td>\n",
       "      <td>Glendale, California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Bioinformatics Scientist</td>\n",
       "      <td>The EAC Agency</td>\n",
       "      <td>Fremont, California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Programmer Anaylyst</td>\n",
       "      <td>Valley First Credit Union</td>\n",
       "      <td>Modesto, California Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analysis Coordinator</td>\n",
       "      <td>The Job Network</td>\n",
       "      <td>Troy, NY, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sr. Manager, Strategic Business Intelligence &amp;...</td>\n",
       "      <td>Project Assistants</td>\n",
       "      <td>Charlotte, NC, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Operations Manager</td>\n",
       "      <td>California Umbrella</td>\n",
       "      <td>92509, Riverside, California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DataStage Developer</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Bellevue, Washington, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sr. Systems Engineer-Data Analysis</td>\n",
       "      <td>Vprecruiter</td>\n",
       "      <td>Bethesda, MD, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Scientist</td>\n",
       "      <td>Nantero</td>\n",
       "      <td>Woburn, Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Procurement Executive – Data Analysis (Contract)</td>\n",
       "      <td>Blue Signal Search</td>\n",
       "      <td>Decatur, IL, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Manager, Data and Analysis</td>\n",
       "      <td>KUOW Public Radio</td>\n",
       "      <td>Seattle, WA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manager of Data Analysis</td>\n",
       "      <td>Summit Public Schools</td>\n",
       "      <td>Redwood City, CA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Management, Analysis &amp; Reporting</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>Newark, DE, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Analysis Manager</td>\n",
       "      <td>Genworth</td>\n",
       "      <td>Richmond, VA, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>ClearedJobs.Net</td>\n",
       "      <td>Redstone Arsenal, AL, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Automation Engineer - Data Analysis/Simulation</td>\n",
       "      <td>Wynright Corporation</td>\n",
       "      <td>Bolingbrook, IL, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Manager of Data Analysis</td>\n",
       "      <td>Summit Public Schools (Public Charter Network)</td>\n",
       "      <td>Redwood City, CA, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                 IT Senior Associate   \n",
       "1   Intern: Data Analysis/Process Improvement Prog...   \n",
       "2   Associate / Business Analyst (Consulting Data ...   \n",
       "3           Software Engineer, Data Models & Analysis   \n",
       "4                Manager, Reporting and Data Analysis   \n",
       "5                               Data Analysis Manager   \n",
       "6     Data Management and Analysis Services Analyst I   \n",
       "7                   Manager, Data Analysis & Insights   \n",
       "8                                        Data Analyst   \n",
       "9                        Sr. Bioinformatics Scientist   \n",
       "10                                Programmer Anaylyst   \n",
       "11                          Data Analysis Coordinator   \n",
       "12  Sr. Manager, Strategic Business Intelligence &...   \n",
       "13                                 Operations Manager   \n",
       "14                                DataStage Developer   \n",
       "15                 Sr. Systems Engineer-Data Analysis   \n",
       "16                                          Scientist   \n",
       "17   Procurement Executive – Data Analysis (Contract)   \n",
       "18                         Manager, Data and Analysis   \n",
       "19                           Manager of Data Analysis   \n",
       "20              Data Management, Analysis & Reporting   \n",
       "21                              Data Analysis Manager   \n",
       "22                                      Data Analysis   \n",
       "23     Automation Engineer - Data Analysis/Simulation   \n",
       "24                           Manager of Data Analysis   \n",
       "\n",
       "                                           Company  \\\n",
       "0                                Kearney & Company   \n",
       "1                                 Juniper Networks   \n",
       "2                        Foresight Associates, LLC   \n",
       "3                                       Improbable   \n",
       "4                The Madison Square Garden Company   \n",
       "5                                      Capital One   \n",
       "6                                         Conduent   \n",
       "7                            The Coca-Cola Company   \n",
       "8                   Viper Staffing Services L.L.C.   \n",
       "9                                   The EAC Agency   \n",
       "10                       Valley First Credit Union   \n",
       "11                                 The Job Network   \n",
       "12                              Project Assistants   \n",
       "13                             California Umbrella   \n",
       "14                                    Confidential   \n",
       "15                                     Vprecruiter   \n",
       "16                                         Nantero   \n",
       "17                              Blue Signal Search   \n",
       "18                               KUOW Public Radio   \n",
       "19                           Summit Public Schools   \n",
       "20                                 Bank of America   \n",
       "21                                        Genworth   \n",
       "22                                 ClearedJobs.Net   \n",
       "23                            Wynright Corporation   \n",
       "24  Summit Public Schools (Public Charter Network)   \n",
       "\n",
       "                                       Location  \n",
       "0                                McLean, VA, US  \n",
       "1                             Sunnyvale, CA, US  \n",
       "2             Greater Minneapolis-St. Paul Area  \n",
       "3                      Washington, D.C., DC, US  \n",
       "4                    Greater New York City Area  \n",
       "5                                McLean, VA, US  \n",
       "6                                Ocoee, Florida  \n",
       "7                               Atlanta, GA, US  \n",
       "8           Glendale, California, United States  \n",
       "9            Fremont, California, United States  \n",
       "10                     Modesto, California Area  \n",
       "11                                 Troy, NY, US  \n",
       "12                            Charlotte, NC, US  \n",
       "13  92509, Riverside, California, United States  \n",
       "14          Bellevue, Washington, United States  \n",
       "15                             Bethesda, MD, US  \n",
       "16                        Woburn, Massachusetts  \n",
       "17                              Decatur, IL, US  \n",
       "18                              Seattle, WA, US  \n",
       "19                         Redwood City, CA, US  \n",
       "20                               Newark, DE, US  \n",
       "21                             Richmond, VA, US  \n",
       "22                     Redstone Arsenal, AL, US  \n",
       "23                          Bolingbrook, IL, US  \n",
       "24                         Redwood City, CA, US  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to call the function\n",
    "\n",
    "results = scrape_linkedin_job_search('data%20analysis')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "The first challenge for you is to update the `scrape_linkedin_job_search` function by adding a new parameter called `num_pages`. This will allow you to search more than 25 jobs with this function. Suggested steps:\n",
    "\n",
    "1. Go to https://www.linkedin.com/jobs/search/?keywords=data%20analysis in your browser.\n",
    "1. Scroll down the left panel and click the page 2 link. Look at how the URL changes and identify the page offset parameter.\n",
    "1. Add `num_pages` as a new param to the `scrape_linkedin_job_search` function. Update the function code so that it uses a \"for\" loop to retrieve several pages of search results.\n",
    "1. Test your new function by scraping 5 pages of the search results.\n",
    "\n",
    "Hint: Prepare for the case where there are less than 5 pages of search results. Your function should be robust enough to **not** trigger errors. Simply skip making additional searches and return all results if the search already reaches the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def scrape_linkedin_job_search_pages(keywords,num_pages):\n",
    "    \n",
    "    \n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    scrape_url = ''.join([BASE_URL, 'keywords=', keywords])\n",
    "\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for num in range(num_pages):\n",
    "        if num == 0:\n",
    "            page = requests.get(scrape_url)\n",
    "        else:\n",
    "            page = requests.get(''.join([scrape_url,'&start=',str(num*25)]))\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        titles = []\n",
    "        companies = []\n",
    "        locations = []\n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "        zipped = zip(titles, companies, locations)\n",
    "        for z in list(zipped):\n",
    "            data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr. Data Analyst – Predictive &amp; Inferential An...</td>\n",
       "      <td>Peyton Resource Group</td>\n",
       "      <td>Arlington, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager, Data and Analysis</td>\n",
       "      <td>Digitas North America</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analysis Manager</td>\n",
       "      <td>Addison Group</td>\n",
       "      <td>Houston, TX, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager, Reporting and Data Analysis</td>\n",
       "      <td>The Madison Square Garden Company</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>iTech Solutions</td>\n",
       "      <td>Philadelphia, Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Brooksource</td>\n",
       "      <td>Philadelphia, Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Partner's Consulting, Inc.</td>\n",
       "      <td>Philadelphia, Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>New York Life Insurance Company</td>\n",
       "      <td>New York City, NY, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>24 Seven LLC</td>\n",
       "      <td>Portland, Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Manager, Data Architecture and Analysis</td>\n",
       "      <td>Verizon Connect</td>\n",
       "      <td>Atlanta, GA, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    Sr. Data Analyst – Predictive & Inferential An...   \n",
       "1                           Manager, Data and Analysis   \n",
       "2                                Data Analysis Manager   \n",
       "3                 Manager, Reporting and Data Analysis   \n",
       "4                                  Senior Data Analyst   \n",
       "..                                                 ...   \n",
       "145                                       Data Analyst   \n",
       "146                                       Data Analyst   \n",
       "147                                       Data Analyst   \n",
       "148                                       Data Analyst   \n",
       "149            Manager, Data Architecture and Analysis   \n",
       "\n",
       "                               Company                    Location  \n",
       "0                Peyton Resource Group            Arlington, Texas  \n",
       "1                Digitas North America  Greater New York City Area  \n",
       "2                        Addison Group             Houston, TX, US  \n",
       "3    The Madison Square Garden Company  Greater New York City Area  \n",
       "4                      iTech Solutions  Philadelphia, Pennsylvania  \n",
       "..                                 ...                         ...  \n",
       "145                        Brooksource  Philadelphia, Pennsylvania  \n",
       "146         Partner's Consulting, Inc.  Philadelphia, Pennsylvania  \n",
       "147    New York Life Insurance Company       New York City, NY, US  \n",
       "148                       24 Seven LLC            Portland, Oregon  \n",
       "149                    Verizon Connect             Atlanta, GA, US  \n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search_pages('data%20analysis',6)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "Further improve your function so that it can search jobs in a specific country. Add the 3rd param to your function called `country`. The steps are identical to those in Challange 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def scrape_linkedin_job_search_pages_country(keywords,num_pages,country):\n",
    "    \n",
    "    \n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    if country==True:\n",
    "        scrape_url = ''.join([BASE_URL, 'keywords=', keywords,])\n",
    "    else:   \n",
    "        scrape_url = ''.join([BASE_URL, 'keywords=', keywords,'&location=',country.replace(\" \",\"%20\")]) \n",
    "        \n",
    "\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for num in range(num_pages):\n",
    "        if num == 0:\n",
    "            page = requests.get(scrape_url)\n",
    "        else:\n",
    "            page = requests.get(''.join([scrape_url,'&start=',str(num*25)]))\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        titles = []\n",
    "        companies = []\n",
    "        locations = []\n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "        zipped = zip(titles, companies, locations)\n",
    "        for z in list(zipped):\n",
    "            data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>EPAM Systems</td>\n",
       "      <td>Kiev, UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst - Marketplace</td>\n",
       "      <td>thredUP</td>\n",
       "      <td>Kiev, UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SalesForce PMO</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>Kiev Region, Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Big Data Software Engineer (ID 40222)</td>\n",
       "      <td>SoftServe</td>\n",
       "      <td>Dnipropetrovsk, Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product Analyst</td>\n",
       "      <td>Toptal</td>\n",
       "      <td>Kharkiv, UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DATA MIGRATION DEVELOPER</td>\n",
       "      <td>INSCALE Global</td>\n",
       "      <td>Kiev, UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Accounting and data analysis specialist, UA</td>\n",
       "      <td>JACOBS DOUWE EGBERTS</td>\n",
       "      <td>Kiev, UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Capital Recruiters</td>\n",
       "      <td>Kiev, UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Company Analytics and Data Intelligence Lead</td>\n",
       "      <td>LifeCell International Pvt.Ltd</td>\n",
       "      <td>Kiev, UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Ring Ukraine</td>\n",
       "      <td>Kiev, UA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title  \\\n",
       "0                              Lead Data Analyst   \n",
       "1              Senior Data Analyst - Marketplace   \n",
       "2                                 SalesForce PMO   \n",
       "3   Senior Big Data Software Engineer (ID 40222)   \n",
       "4                                Product Analyst   \n",
       "..                                           ...   \n",
       "95                      DATA MIGRATION DEVELOPER   \n",
       "96   Accounting and data analysis specialist, UA   \n",
       "97                         Data Science Engineer   \n",
       "98  Company Analytics and Data Intelligence Lead   \n",
       "99                                  Data Analyst   \n",
       "\n",
       "                           Company                 Location  \n",
       "0                     EPAM Systems                 Kiev, UA  \n",
       "1                          thredUP                 Kiev, UA  \n",
       "2                           Luxoft     Kiev Region, Ukraine  \n",
       "3                        SoftServe  Dnipropetrovsk, Ukraine  \n",
       "4                           Toptal              Kharkiv, UA  \n",
       "..                             ...                      ...  \n",
       "95                  INSCALE Global                 Kiev, UA  \n",
       "96            JACOBS DOUWE EGBERTS                 Kiev, UA  \n",
       "97              Capital Recruiters                 Kiev, UA  \n",
       "98  LifeCell International Pvt.Ltd                 Kiev, UA  \n",
       "99                    Ring Ukraine                 Kiev, UA  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search_pages_country('data%20analysis',4,'UK')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "Add the 4th param called `num_days` to your function to allow it to search jobs posted in the past X days. Note that in the LinkedIn job search the searched timespan is specified with the following param:\n",
    "\n",
    "```\n",
    "f_TPR=r259200\n",
    "```\n",
    "\n",
    "The number part in the param value is the number of seconds. 259,200 seconds equal to 3 days. You need to convert `num_days` to number of seconds and supply that info to LinkedIn job search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def scrape_linkedin_job_search_pages_country_days(keywords,num_pages,country,num_days):\n",
    "    \n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    scrape_url = ''.join([BASE_URL, 'keywords=', keywords,'&location=',country.replace(\" \",\"%20\"),'f_TPR=r',str(num_days*86400)]) \n",
    "        \n",
    "        \n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for num in range(num_pages):\n",
    "        if num == 0:\n",
    "            page = requests.get(scrape_url)\n",
    "        else:\n",
    "            page = requests.get(''.join([scrape_url,'&start=',str(num*25)]))\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        titles = []\n",
    "        companies = []\n",
    "        locations = []\n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "        zipped = zip(titles, companies, locations)\n",
    "        for z in list(zipped):\n",
    "            data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr. Data Engineer</td>\n",
       "      <td>Cypress HCM</td>\n",
       "      <td>Miami/Fort Lauderdale Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Dynamo, LLC.</td>\n",
       "      <td>Greater Omaha Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Architect</td>\n",
       "      <td>SessionM</td>\n",
       "      <td>Greater Boston Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Strategic Data Analyst (SAS &amp; Tableau) Lo...</td>\n",
       "      <td>Compass Technology Group</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IT Data Analyst</td>\n",
       "      <td>Navigant</td>\n",
       "      <td>Gardena, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Manager, Reporting and Data Analysis</td>\n",
       "      <td>The Madison Square Garden Company</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Viper Staffing Services L.L.C.</td>\n",
       "      <td>Glendale, California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Sr. Bioinformatics Scientist</td>\n",
       "      <td>The EAC Agency</td>\n",
       "      <td>Fremont, California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Programmer Anaylyst</td>\n",
       "      <td>Valley First Credit Union</td>\n",
       "      <td>Modesto, California Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Data Analysis Coordinator</td>\n",
       "      <td>The Job Network</td>\n",
       "      <td>Troy, NY, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                   Sr. Data Engineer   \n",
       "1                                Senior Data Engineer   \n",
       "2                                      Data Architect   \n",
       "3   Lead Strategic Data Analyst (SAS & Tableau) Lo...   \n",
       "4                                     IT Data Analyst   \n",
       "..                                                ...   \n",
       "95               Manager, Reporting and Data Analysis   \n",
       "96                                       Data Analyst   \n",
       "97                       Sr. Bioinformatics Scientist   \n",
       "98                                Programmer Anaylyst   \n",
       "99                          Data Analysis Coordinator   \n",
       "\n",
       "                              Company                             Location  \n",
       "0                         Cypress HCM           Miami/Fort Lauderdale Area  \n",
       "1                        Dynamo, LLC.                   Greater Omaha Area  \n",
       "2                            SessionM                  Greater Boston Area  \n",
       "3            Compass Technology Group                        Dallas, Texas  \n",
       "4                            Navigant                  Gardena, California  \n",
       "..                                ...                                  ...  \n",
       "95  The Madison Square Garden Company           Greater New York City Area  \n",
       "96     Viper Staffing Services L.L.C.  Glendale, California, United States  \n",
       "97                     The EAC Agency   Fremont, California, United States  \n",
       "98          Valley First Credit Union             Modesto, California Area  \n",
       "99                    The Job Network                         Troy, NY, US  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = scrape_linkedin_job_search_pages_country_days('data%20analysis',4,'United Kingdom',2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Allow your function to also retrieve the \"Seniority Level\" of each job searched. Note that the Seniority Level info is not in the initial search results. You need to make a separate search request for each job card based on the `currentJobId` value which you can extract from the job card HTML.\n",
    "\n",
    "After you obtain the Seniority Level info, update the function and add it to a new column of the returned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# your code here\n",
    "\n",
    "def scrape_linkedin_job_search_advanced(keywords,num_pages,country,num_days):\n",
    "    \n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    scrape_url = ''.join([BASE_URL, 'keywords=', keywords,'&location=',country.replace(\" \",\"%20\"),'f_TPR=r',str(num_days*86400)]) \n",
    "        \n",
    "        \n",
    "    columns = ['Title', 'Company', 'Location','CurrentJobId']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for num in range(num_pages):\n",
    "        if num == 0:\n",
    "            page = requests.get(scrape_url)\n",
    "        else:\n",
    "            page = requests.get(''.join([scrape_url,'&start=',str(num*25)]))\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        titles = []\n",
    "        companies = []\n",
    "        locations = []\n",
    "        jobID = []\n",
    "        for card in soup.select(\"div.result-card__contents\"):\n",
    "            title = card.findChild(\"h3\", recursive=False)\n",
    "            company = card.findChild(\"h4\", recursive=False)\n",
    "            location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "            jobID = card.find('a',attrs={\"href\": \"job-result-card__location\"})\n",
    "            titles.append(title.string)\n",
    "            companies.append(company.string)\n",
    "            locations.append(location.string)\n",
    "            jobID.append(job_ID)\n",
    "        zipped = zip(titles, companies, locations, jobID)\n",
    "        for z in list(zipped):\n",
    "            data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2] , 'CurrentJobId':z[3]}, ignore_index=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Software Engineer - Data Mining/Data Analysis/Machine Learning</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/linkedin?trk=guest_job_search_job-result-card_result-card_subtitle-click\">LinkedIn</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Sunnyvale</span><p class=\"job-result-card__snippet\">The ideal candidate will have domain experience (data mining, information retrieval, security data science, natural language processing, ...</p><time class=\"job-result-card__listdate--new\" datetime=\"2019-10-28\">Just now</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Sr. Data Analyst – Predictive &amp; Inferential Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/peyton-resource-group?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Peyton Resource Group</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Arlington, Texas</span><p class=\"job-result-card__snippet\">Proficient skills doing data discovery in an EDW or data lake environment. Proficient skills using Tableau, Power BI, Cognos, or ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-11\">2 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Data Analysis Manager</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/capital-one?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Capital One</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">McLean, VA, US</span><p class=\"job-result-card__snippet\">An ideal candidate will be on the leading edge of Analytical technology with a passion for the newest and most innovative tools. Still ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-27\">1 day ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Senior Manager of Data Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://nl.linkedin.com/company/philips?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Philips</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Boston, MA, US</span><p class=\"job-result-card__snippet\">To succeed in this role, you should have the following skills and experience. It is our mission to improve people’s lives through ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-12\">2 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Software Engineer, Data Models &amp; Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://uk.linkedin.com/company/improbable?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Improbable</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Washington, D.C., DC, US</span><p class=\"job-result-card__snippet\">Using your broad software engineering experience, you will choose the most appropriate language/technologies for the project at hand; ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-27\">2 days ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">BUSINESS ANALYST-Marketing and Data Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/ashlin-management-group?trk=guest_job_search_job-result-card_result-card_subtitle-click\">ASHLIN Management Group</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">20721, Bowie, Maryland, United States</span><p class=\"job-result-card__snippet\">The Business Analyst position is responsible for understanding business process management and business requirements of the client. This ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-15\">2 weeks ago</time><span class=\"job-result-card__easy-apply-label\">Easy Apply</span></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Supervisor, Data Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/quartz-health-solutions?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Quartz Health Solutions</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Madison, Wisconsin, United States</span><span class=\"job-result-card__salary-info\">$85,000.00 - $110,000.00</span><p class=\"job-result-card__snippet\">Quartz is seeking a technical, analytical leader to join our growing Data Warehouse Department as a Supervisor, Data Analysis. Strong ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-24\">4 days ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Manager, Data Architecture and Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/verizon-connect?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Verizon Connect</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Atlanta, GA, US</span><p class=\"job-result-card__snippet\">What we’re looking for... Even Better If You Have. Together we’ll go far. Six or more years of general data architecture experience. ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-22\">6 days ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Core Data - Data Analyst/ Data Architect</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/apple?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Apple</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Cupertino, CA, US</span><p class=\"job-result-card__snippet\">This role is inherently cross-functional and the ideal candidate will work across disciplines. We are looking for someone with a love for...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-12\">2 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Manager, Data and Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/digitas-north-america?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Digitas North America</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Greater New York City Area</span><p class=\"job-result-card__snippet\">We’re looking for strong, impactful work experience, which typically includes: To help with this, we’re looking for an outstanding ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-17\">2 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Data Intelligence Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/consumer-reports?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Consumer Reports</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Yonkers, NY, US</span><p class=\"job-result-card__snippet\">The data intelligence program brings in critical revenue to support CR’s mission-oriented work while simultaneously driving upstream ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-10\">3 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Associate / Business Analyst (Consulting Data Analysis)</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/foresight-associates-llc?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Foresight Associates, LLC</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Greater Minneapolis-St. Paul Area</span><p class=\"job-result-card__snippet\">Business Analyst Level (Salary 45K plus bonus) 0-2 years non-academic experience applied to business problems and or relevant school ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-21\">1 week ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Financial Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/pinnacle-technical-resources?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Pinnacle Group, Inc.</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Dallas/Fort Worth Area</span><p class=\"job-result-card__snippet\">A strong financial acumen, quantitative and data analysis skills. Strong organizational and stakeholder management skills. Strong verbal,...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-23\">5 days ago</time><span class=\"job-result-card__easy-apply-label\">Easy Apply</span></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Senior Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/optimizely?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Optimizely</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">San Francisco, CA, US</span><p class=\"job-result-card__snippet\">Optimizely is looking for a mid-to-senior level Data Analyst who can provide actionable insight through a combination of data ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-11\">2 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/24-7-wall-st-?trk=guest_job_search_job-result-card_result-card_subtitle-click\">24/7 Wall St.</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Greater New York City Area</span><p class=\"job-result-card__snippet\">24/7 Wall St. is looking for a data analyst to work closely with its editorial and business intelligence teams. Experience with Python, ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-23\">5 days ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Sr. Manager, Strategic Business Intelligence &amp; Data Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/project-assistants?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Project Assistants</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Charlotte, North Carolina Area</span><p class=\"job-result-card__snippet\">     Experience with the leading BI, analytical and visualization tools such as Tableau, Microsoft, SAP and Qlik required.      ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-15\">2 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Senior Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/trexin-consulting?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Trexin Consulting</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Chicago, Illinois</span><p class=\"job-result-card__snippet\">Key Desired Skills, Experience and Knowledge. Trexin Consulting is currently seeking a Technical Data Analyst to join our team in Chicago...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-14\">2 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Master Data Management Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/search-masters-inc.?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Search Masters, Inc.</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Bedford, Ohio</span><p class=\"job-result-card__snippet\">Prior accounting experience in a manufacturing facility is required. Will be responsible for financial reporting for capital approvals, ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-23\">5 days ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Modelling Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://au.linkedin.com/company/transurban?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Transurban</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Fairfax County, VA, US</span><p class=\"job-result-card__snippet\">At Transurban, we are on a mission to strengthen communities through transportation. Well-developed numerical skills and demonstrated ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-18\">1 week ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Manager, Reporting and Data Analysis</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/the-madison-square-garden-company?trk=guest_job_search_job-result-card_result-card_subtitle-click\">The Madison Square Garden Company</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Greater New York City Area</span><p class=\"job-result-card__snippet\">Advanced Microsoft Access and Excel skills, including proficiency with complex pivot tables and data analysis functions. Analytical ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-23\">5 days ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://ch.linkedin.com/company/modis?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Modis</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Chicago, Illinois</span><p class=\"job-result-card__snippet\">The Data Analyst is responsible for data modeling and analytics.       Leverages technology to design and develop quantitative and ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-15\">2 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/experis?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Experis</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">San Antonio, TX, US</span><p class=\"job-result-card__snippet\">A top company in San Antonio is seeking a Data Analyst for an 8 month contract with likely extensions. 5+ years of experience in working ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-11\">3 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Data Analysis Manager</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/addisongroup?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Addison Group</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Houston, TX, US</span><p class=\"job-result-card__snippet\">Clear communication skills and experience partnering with business functions/units to define, design, and implement best practices for ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-08\">3 weeks ago</time></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/brooksource?trk=guest_job_search_job-result-card_result-card_subtitle-click\">Brooksource</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Philadelphia, Pennsylvania</span><p class=\"job-result-card__snippet\">Pay Rate: $20.00  - $22.00 (Depending on Experience) Strong SQL experience, openness to learn SSIS. 0-1-year experience in enterprise ...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-17\">2 weeks ago</time><span class=\"job-result-card__easy-apply-label\">Easy Apply</span></div></div>,\n",
       " <div class=\"result-card__contents job-result-card__contents\"><h3 class=\"result-card__title job-result-card__title\">Data Analyst</h3><h4 class=\"result-card__subtitle job-result-card__subtitle\"><a class=\"result-card__subtitle-link job-result-card__subtitle-link\" data-tracking-control-name=\"guest_job_search_job-result-card_result-card_subtitle-click\" data-tracking-will-navigate=\"\" href=\"https://www.linkedin.com/company/fedex-services?trk=guest_job_search_job-result-card_result-card_subtitle-click\">FedEx Services</a></h4><div class=\"result-card__meta job-result-card__meta\"><span class=\"job-result-card__location\">Memphis, TN, US</span><p class=\"job-result-card__snippet\">Two (2) years work experience in measurement and analysis, quantitative business problem solving, operations analysis, marketing analysis...</p><time class=\"job-result-card__listdate\" datetime=\"2019-10-22\">7 days ago</time></div></div>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_URL = 'https://www.linkedin.com/jobs/search/?&f_TPR=r86400&keywords=data%20analysis'\n",
    "page = requests.get(BASE_URL)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "soup.select(\"div.result-card__contents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-e86af771404e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscrape_linkedin_job_search_advanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data%20analysis'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'United Kingdom'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-132-489141abc9d0>\u001b[0m in \u001b[0;36mscrape_linkedin_job_search_advanced\u001b[0;34m(keywords, num_pages, country, num_days)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mcompanies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mlocations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mjobID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mzipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompanies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "scrape_linkedin_job_search_advanced('data%20analysis',4,'United Kingdom',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
